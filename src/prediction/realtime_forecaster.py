#!/usr/bin/env python3
"""
Real-Time Power Demand Forecaster with Weather Forecast Integration

This module implements the real-time prediction system outlined in Phase 6 of
planning/weather_forecast_integration.md. It demonstrates the value of weather
forecast features for power demand prediction by comparing baseline vs 
forecast-enhanced predictions on current data.

The system provides:
- Real-time power demand predictions (1-48 hours ahead)
- Baseline predictions (historical patterns only)
- Forecast-enhanced predictions (with weather forecasts)
- Performance comparison and improvement measurement
- Confidence intervals and uncertainty quantification

Author: ML Power Nowcast System
Created: 2025-08-29
"""

import logging
from datetime import datetime, timedelta, timezone
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Union

import numpy as np
import pandas as pd
from dataclasses import dataclass

from ..models.enhanced_xgboost import EnhancedXGBoostModel
from ..models.lightgbm_model import LightGBMModel
from ..features.unified_feature_pipeline import (
    build_unified_features,
    UnifiedFeatureConfig,
    ForecastFeatureConfig
)

# Configure logging
logger = logging.getLogger(__name__)


@dataclass
class PredictionConfig:
    """
    Configuration for real-time predictions.
    
    Attributes:
        prediction_horizons: List of prediction horizons in hours
        confidence_levels: List of confidence levels for intervals
        baseline_model_path: Path to baseline model file
        enhanced_model_path: Path to enhanced model file
        target_zones: List of CAISO zones to predict
        update_frequency_minutes: How often to update predictions
    """
    prediction_horizons: List[int]
    confidence_levels: List[float] = None
    baseline_model_path: Optional[Path] = None
    enhanced_model_path: Optional[Path] = None
    target_zones: List[str] = None
    update_frequency_minutes: int = 30
    
    def __post_init__(self):
        """Set defaults for optional parameters."""
        if self.confidence_levels is None:
            self.confidence_levels = [0.80, 0.90, 0.95]
        
        if self.target_zones is None:
            self.target_zones = ['NP15']


@dataclass
class PredictionResult:
    """
    Container for prediction results.
    
    Attributes:
        timestamp: Prediction timestamp
        zone: CAISO zone
        horizon_hours: Prediction horizon in hours
        baseline_prediction: Baseline model prediction
        enhanced_prediction: Enhanced model prediction (with forecasts)
        confidence_intervals: Dictionary of confidence intervals
        forecast_improvement_pct: Percentage improvement from forecasts
        prediction_metadata: Additional metadata
    """
    timestamp: datetime
    zone: str
    horizon_hours: int
    baseline_prediction: float
    enhanced_prediction: Optional[float]
    lightgbm_prediction: Optional[float]
    confidence_intervals: Dict[float, Tuple[float, float]]
    forecast_improvement_pct: Optional[float]
    prediction_metadata: Dict[str, any]


class RealtimeForecasterError(Exception):
    """Base exception for real-time forecaster operations."""
    pass


class ModelLoadError(RealtimeForecasterError):
    """Raised when model loading fails."""
    pass


class PredictionError(RealtimeForecasterError):
    """Raised when prediction generation fails."""
    pass


class RealtimeForecaster:
    """
    Real-time power demand forecaster with weather forecast integration.
    
    This class implements the complete real-time prediction system as specified
    in the weather forecast integration plan, demonstrating the value of weather
    forecast features for power demand prediction.
    """
    
    def __init__(self, config: PredictionConfig):
        """
        Initialize real-time forecaster.
        
        Args:
            config: Prediction configuration
        """
        self.config = config
        self.baseline_model = None
        self.enhanced_model = None
        self.lightgbm_model = None
        self.is_initialized = False
        
    def initialize(self) -> None:
        """
        Initialize the forecaster by loading trained models.
        
        Raises:
            ModelLoadError: If model loading fails
        """
        logger.info("Initializing real-time forecaster")
        
        try:
            # Load baseline model
            if self.config.baseline_model_path and self.config.baseline_model_path.exists():
                self.baseline_model = EnhancedXGBoostModel.load_model(self.config.baseline_model_path)
                logger.info(f"Loaded baseline model from {self.config.baseline_model_path}")
            else:
                logger.warning("No baseline model path provided or file not found")
            
            # Load enhanced model
            if self.config.enhanced_model_path and self.config.enhanced_model_path.exists():
                self.enhanced_model = EnhancedXGBoostModel.load_model(self.config.enhanced_model_path)
                logger.info(f"Loaded enhanced model from {self.config.enhanced_model_path}")
            else:
                logger.warning("No enhanced model path provided or file not found")



            # Load zone-specific LightGBM model (FIXED: was loading global model)
            lightgbm_model_dir = Path("data/trained_models")
            if lightgbm_model_dir.exists() and self.config.target_zones:
                # Try to load zone-specific LightGBM model for the first target zone
                target_zone = self.config.target_zones[0]
                zone_lightgbm_files = list(lightgbm_model_dir.glob(f"lightgbm_model_{target_zone}_*.joblib"))

                if zone_lightgbm_files:
                    # Get the most recent zone-specific LightGBM model
                    latest_lightgbm = max(zone_lightgbm_files, key=lambda p: p.stat().st_mtime)
                    try:
                        self.lightgbm_model = LightGBMModel.load_model(latest_lightgbm)
                        logger.info(f"Loaded zone-specific LightGBM model for {target_zone} from {latest_lightgbm}")
                    except Exception as e:
                        logger.warning(f"Failed to load zone-specific LightGBM model for {target_zone}: {e}")
                else:
                    # Fallback to global LightGBM model (legacy support)
                    lightgbm_files = list(lightgbm_model_dir.glob("lightgbm_model_*.joblib"))
                    # Filter out zone-specific models to get global ones
                    global_lightgbm_files = [f for f in lightgbm_files if not any(zone in f.name for zone in ['NP15', 'SCE', 'SDGE', 'SP15', 'SMUD', 'PGE_VALLEY', 'SYSTEM'])]

                    if global_lightgbm_files:
                        latest_lightgbm = max(global_lightgbm_files, key=lambda p: p.stat().st_mtime)
                        try:
                            self.lightgbm_model = LightGBMModel.load_model(latest_lightgbm)
                            logger.warning(f"Using global LightGBM model for {target_zone} from {latest_lightgbm} (zone-specific model not found)")
                        except Exception as e:
                            logger.warning(f"Failed to load global LightGBM model: {e}")
                    else:
                        logger.warning(f"No LightGBM model files found for zone {target_zone}")
            else:
                logger.warning("No LightGBM model directory found or no target zones specified")

            if not self.baseline_model and not self.enhanced_model and not self.lightgbm_model:
                raise ModelLoadError("No models could be loaded")
            
            self.is_initialized = True
            logger.info("Real-time forecaster initialized successfully")
            
        except Exception as e:
            raise ModelLoadError(f"Failed to initialize forecaster: {e}")

    def prepare_horizon_features(
        self,
        target_time: datetime,
        zone: str,
        latest_records: pd.DataFrame
    ) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """
        Prepare features for a specific horizon using pre-loaded power data.

        Args:
            target_time: Target time for prediction
            zone: CAISO zone
            latest_records: Pre-loaded recent power records

        Returns:
            Tuple of (baseline_features, enhanced_features)
        """
        try:
            # Create a single row for the target time with temporal features
            feature_row = pd.DataFrame({
                'timestamp': [target_time],
                'zone': [zone]
            })

            # Create temporal features for the target time
            feature_row['hour'] = target_time.hour
            feature_row['day_of_week'] = target_time.weekday()
            feature_row['day_of_year'] = target_time.timetuple().tm_yday
            feature_row['month'] = target_time.month
            feature_row['quarter'] = (target_time.month - 1) // 3 + 1
            feature_row['is_weekend'] = int(target_time.weekday() >= 5)

            # Create cyclical features
            import numpy as np
            feature_row['hour_sin'] = np.sin(2 * np.pi * target_time.hour / 24)
            feature_row['hour_cos'] = np.cos(2 * np.pi * target_time.hour / 24)
            feature_row['day_of_week_sin'] = np.sin(2 * np.pi * target_time.weekday() / 7)
            feature_row['day_of_week_cos'] = np.cos(2 * np.pi * target_time.weekday() / 7)
            feature_row['day_of_year_sin'] = np.sin(2 * np.pi * target_time.timetuple().tm_yday / 365.25)
            feature_row['day_of_year_cos'] = np.cos(2 * np.pi * target_time.timetuple().tm_yday / 365.25)

            # Add lag features from the most recent data
            if len(latest_records) >= 1:
                feature_row['load_lag_1h'] = latest_records.iloc[-1]['load']
            if len(latest_records) >= 24:
                feature_row['load_lag_24h'] = latest_records.iloc[-24]['load']

            # Prepare baseline features in exact order expected by the model
            baseline_features = [
                'hour', 'day_of_week', 'month', 'quarter', 'is_weekend',
                'hour_sin', 'hour_cos', 'day_of_week_sin', 'day_of_week_cos',
                'day_of_year_sin', 'day_of_year_cos',
                'load_lag_1h', 'load_lag_24h'
            ]

            # Ensure all baseline features are present and in correct order
            baseline_df = pd.DataFrame()
            for feature in baseline_features:
                if feature in feature_row.columns:
                    baseline_df[feature] = feature_row[feature]
                else:
                    # Fill missing features with defaults
                    if 'lag' in feature:
                        baseline_df[feature] = 0.0  # Default lag value
                    else:
                        baseline_df[feature] = feature_row.get(feature, 0.0)

            # Create extreme temporal features for maximum pattern learning
            from src.models.production_config import create_extreme_temporal_features

            # Convert baseline_df to proper format for enhanced feature creation
            temp_df = baseline_df.copy()
            temp_df['timestamp'] = target_time
            temp_df['zone'] = zone
            temp_df['load'] = 0.0  # Placeholder

            # Add basic temporal features that enhanced features depend on
            temp_df['hour'] = target_time.hour
            temp_df['day_of_week'] = target_time.weekday()
            temp_df['month'] = target_time.month
            temp_df['quarter'] = (target_time.month - 1) // 3 + 1
            temp_df['is_weekend'] = int(target_time.weekday() >= 5)

            # Add cyclical features
            import numpy as np
            temp_df['hour_sin'] = np.sin(2 * np.pi * target_time.hour / 24)
            temp_df['hour_cos'] = np.cos(2 * np.pi * target_time.hour / 24)
            temp_df['day_of_week_sin'] = np.sin(2 * np.pi * target_time.weekday() / 7)
            temp_df['day_of_week_cos'] = np.cos(2 * np.pi * target_time.weekday() / 7)
            temp_df['day_of_year_sin'] = np.sin(2 * np.pi * target_time.timetuple().tm_yday / 365.25)
            temp_df['day_of_year_cos'] = np.cos(2 * np.pi * target_time.timetuple().tm_yday / 365.25)

            # Create extreme temporal features
            enhanced_temp_df = create_extreme_temporal_features(temp_df)

            # Extract enhanced features (keep zone for feature preparation)
            enhanced_df = enhanced_temp_df.drop(columns=['timestamp', 'load'], errors='ignore')

            # Load real weather data for accurate predictions
            try:
                from pathlib import Path
                weather_path = Path("data/weather_all_zones_sample.parquet")
                if weather_path.exists():
                    weather_df = pd.read_parquet(weather_path)
                    
                    # Get weather data for the target zone and time
                    zone_weather = weather_df[weather_df['zone'] == zone]
                    if len(zone_weather) > 0:
                        # Find closest weather record to target time
                        zone_weather['timestamp'] = pd.to_datetime(zone_weather['timestamp'])
                        closest_weather = zone_weather.iloc[(zone_weather['timestamp'] - target_time.replace(tzinfo=None)).abs().argsort()[:1]]
                        
                        if len(closest_weather) > 0:
                            weather_record = closest_weather.iloc[0]
                            temp_c = float(weather_record.get('temp_c', 20.0))
                            humidity = float(weather_record.get('humidity', 50.0))
                            
                            # Add real weather features
                            enhanced_df['temp_c'] = temp_c
                            enhanced_df['humidity'] = humidity
                            enhanced_df['temp_c_squared'] = temp_c ** 2
                            enhanced_df['cooling_degree_days'] = max(temp_c - 18.0, 0)
                            enhanced_df['heating_degree_days'] = max(18.0 - temp_c, 0)
                            enhanced_df['temp_humidity_interaction'] = temp_c * humidity / 100.0
                            enhanced_df['heat_index_approx'] = temp_c + 0.5 * humidity / 10.0
                            
                            # Weather forecast features
                            enhanced_df['temp_forecast_6h'] = temp_c
                            enhanced_df['temp_forecast_24h'] = temp_c
                            enhanced_df['cooling_forecast_6h'] = max(temp_c - 18.0, 0)
                            enhanced_df['heating_forecast_6h'] = max(18.0 - temp_c, 0)
                            enhanced_df['temp_change_rate_6h'] = 0.0  # Simplified
                            enhanced_df['weather_volatility_6h'] = abs(temp_c - 20.0)  # Volatility from normal
                        else:
                            # Fallback to defaults if no weather data
                            self._add_default_weather_features(enhanced_df)
                    else:
                        # Fallback to defaults if no zone weather
                        self._add_default_weather_features(enhanced_df)
                else:
                    # Fallback to defaults if no weather file
                    self._add_default_weather_features(enhanced_df)
            except Exception as e:
                # Fallback to defaults on any error
                self._add_default_weather_features(enhanced_df)

            return baseline_df, enhanced_df

        except Exception as e:
            raise PredictionError(f"Failed to prepare horizon features: {e}")

    def _add_default_weather_features(self, enhanced_df: pd.DataFrame) -> None:
        """Add default weather features when real weather data is unavailable."""
        enhanced_df['temp_c'] = 20.0
        enhanced_df['humidity'] = 50.0
        enhanced_df['temp_c_squared'] = 400.0
        enhanced_df['cooling_degree_days'] = max(20.0 - 18.0, 0)
        enhanced_df['heating_degree_days'] = max(18.0 - 20.0, 0)
        enhanced_df['temp_humidity_interaction'] = 10.0
        enhanced_df['heat_index_approx'] = 22.5
        enhanced_df['temp_forecast_6h'] = 20.0
        enhanced_df['temp_forecast_24h'] = 20.0
        enhanced_df['cooling_forecast_6h'] = max(20.0 - 18.0, 0)
        enhanced_df['heating_forecast_6h'] = max(18.0 - 20.0, 0)
        enhanced_df['temp_change_rate_6h'] = 0.0
        enhanced_df['weather_volatility_6h'] = 0.0

    def _create_enhanced_features_with_pipeline(
        self,
        target_time: datetime,
        zone: str,
        latest_records: pd.DataFrame,
        baseline_df: pd.DataFrame
    ) -> pd.DataFrame:
        """
        Create enhanced features using the unified feature pipeline.
        Falls back to default values if pipeline fails.
        """
        try:
            # Create extended dataset for feature pipeline
            extended_records = latest_records.copy()

            # Add target time as future record
            target_row = pd.DataFrame({
                'timestamp': [target_time],
                'zone': [zone],
                'load': [np.nan]  # Future load is unknown
            })

            # Combine historical and target data
            combined_df = pd.concat([extended_records, target_row], ignore_index=True)
            combined_df['timestamp'] = pd.to_datetime(combined_df['timestamp'])
            combined_df = combined_df.sort_values('timestamp').reset_index(drop=True)

            # Configure unified feature pipeline
            config = UnifiedFeatureConfig(
                forecast_config=ForecastFeatureConfig(
                    forecast_horizons=[6, 24],
                    base_temperature=18.0
                ),
                include_lag_features=True,
                lag_hours=[1, 24],
                include_temporal_features=True,
                include_weather_interactions=True,   # Weather data now available
                target_zones=[zone]
            )

            # Save temporary data for pipeline
            temp_path = Path("data/temp_prediction_data.parquet")
            temp_path.parent.mkdir(exist_ok=True)
            combined_df.to_parquet(temp_path, index=False)

            try:
                # Build features using unified pipeline
                weather_path = Path("data/weather_all_zones_sample.parquet")
                features_df = build_unified_features(
                    power_data_path=temp_path,
                    weather_data_path=weather_path if weather_path.exists() else None,
                    forecast_data_dir=None,
                    config=config
                )

                # Get features for target time
                target_features = features_df[
                    features_df['timestamp'] == target_time
                ].copy()

                if len(target_features) > 0:
                    # Extract enhanced features
                    enhanced_columns = list(baseline_df.columns) + [
                        col for col in target_features.columns
                        if 'forecast' in col.lower() or 'temp_' in col or 'cooling_' in col or 'heating_' in col
                    ]

                    available_enhanced = [col for col in enhanced_columns if col in target_features.columns]
                    enhanced_df = target_features[available_enhanced].copy()

                    # Add any missing forecast features with defaults
                    forecast_defaults = {
                        'temp_forecast_6h': 20.0,
                        'temp_forecast_24h': 20.0,
                        'cooling_forecast_6h': 0.0,
                        'heating_forecast_6h': 0.0,
                        'temp_change_rate_6h': 0.0,
                        'weather_volatility_6h': 0.0
                    }

                    for feature, default_value in forecast_defaults.items():
                        if feature not in enhanced_df.columns:
                            enhanced_df[feature] = default_value

                    return enhanced_df

            finally:
                # Clean up temporary file
                temp_path.unlink(missing_ok=True)

        except Exception as e:
            logger.warning(f"Enhanced feature pipeline failed: {e}, using defaults")

        # Fallback: use baseline features with default forecast values
        enhanced_df = baseline_df.copy()
        enhanced_df['temp_forecast_6h'] = 20.0
        enhanced_df['temp_forecast_24h'] = 20.0
        enhanced_df['cooling_forecast_6h'] = 0.0
        enhanced_df['heating_forecast_6h'] = 0.0
        enhanced_df['temp_change_rate_6h'] = 0.0
        enhanced_df['weather_volatility_6h'] = 0.0

        return enhanced_df

    def prepare_prediction_features(
        self,
        target_time: datetime,
        zone: str
    ) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """
        Prepare features for baseline and enhanced predictions at a specific target time.
        Legacy method - use prepare_horizon_features for better performance.

        Args:
            target_time: Target time for which to make predictions
            zone: CAISO zone to predict

        Returns:
            Tuple of (baseline_features, enhanced_features)

        Raises:
            PredictionError: If feature preparation fails
        """
        try:
            logger.debug(f"Preparing prediction features for {zone} at {target_time}")

            # Load the most recent power data to get lag features
            # Use absolute path from project root
            from pathlib import Path
            project_root = Path(__file__).parent.parent.parent
            data_path = project_root / "data" / "master" / "caiso_california_only.parquet"
            power_df = pd.read_parquet(data_path)
            zone_power = power_df[power_df['zone'] == zone].copy()
            zone_power['timestamp'] = pd.to_datetime(zone_power['timestamp'])
            zone_power = zone_power.sort_values('timestamp')

            # Get the most recent records for lag features
            latest_records = zone_power.tail(25).copy()  # Get enough for 24h lag

            # Use the optimized method
            return self.prepare_horizon_features(target_time, zone, latest_records)

        except Exception as e:
            raise PredictionError(f"Failed to prepare prediction features: {e}")
    
    def make_predictions(
        self,
        prediction_time: datetime,
        zone: str,
        horizons: List[int]
    ) -> List[PredictionResult]:
        """
        Make baseline and enhanced predictions for specified horizons.

        Args:
            prediction_time: Time for which to make predictions
            zone: CAISO zone to predict
            horizons: List of prediction horizons in hours

        Returns:
            List of PredictionResult objects

        Raises:
            PredictionError: If prediction generation fails
        """
        if not self.is_initialized:
            raise PredictionError("Forecaster not initialized. Call initialize() first.")

        logger.info(f"Making predictions for {zone} at {prediction_time}")

        try:
            # Load power data once for all horizons
            # Use absolute path from project root
            from pathlib import Path
            project_root = Path(__file__).parent.parent.parent
            data_path = project_root / "data" / "master" / "caiso_california_only.parquet"
            power_df = pd.read_parquet(data_path)
            zone_power = power_df[power_df['zone'] == zone].copy()
            zone_power['timestamp'] = pd.to_datetime(zone_power['timestamp'])
            zone_power = zone_power.sort_values('timestamp')

            # Get the most recent records for lag features
            latest_records = zone_power.tail(25).copy()  # Get enough for 24h lag

            if len(latest_records) == 0:
                raise PredictionError(f"No power data available for zone {zone}")

            results = []

            for horizon in horizons:
                # Calculate the target timestamp for this horizon
                target_time = prediction_time + timedelta(hours=horizon)

                # Prepare features specific to this horizon's timestamp
                baseline_features, enhanced_features = self.prepare_horizon_features(
                    target_time, zone, latest_records
                )

                # Make baseline prediction
                baseline_pred = None
                if self.baseline_model:
                    try:
                        baseline_pred = self.baseline_model.predict(baseline_features)[0]
                    except Exception as e:
                        logger.warning(f"Baseline prediction failed for horizon {horizon}h: {e}")

                # Make enhanced prediction
                enhanced_pred = None
                if self.enhanced_model:
                    try:
                        enhanced_pred = self.enhanced_model.predict(enhanced_features)[0]
                    except Exception as e:
                        logger.warning(f"Enhanced prediction failed for horizon {horizon}h: {e}")

                # Make LightGBM prediction
                lightgbm_pred = None
                if self.lightgbm_model:
                    try:
                        lightgbm_pred = self.lightgbm_model.predict(enhanced_features)[0]
                    except Exception as e:
                        logger.warning(f"LightGBM prediction failed for horizon {horizon}h: {e}")


                # Calculate improvement
                improvement_pct = None
                if baseline_pred and enhanced_pred and baseline_pred != 0:
                    improvement_pct = ((enhanced_pred - baseline_pred) / baseline_pred) * 100
                
                # Create confidence intervals (simplified approach)
                confidence_intervals = {}
                if enhanced_pred:
                    for conf_level in self.config.confidence_levels:
                        # Simple approach: Â±10% for 95% confidence, scaled for other levels
                        margin = enhanced_pred * 0.10 * (conf_level / 0.95)
                        confidence_intervals[conf_level] = (
                            enhanced_pred - margin,
                            enhanced_pred + margin
                        )
                
                # Check for forecast feature availability
                forecast_available = enhanced_features['temp_forecast_6h'].notna().any() if 'temp_forecast_6h' in enhanced_features.columns else False
                
                # Create prediction result
                result = PredictionResult(
                    timestamp=target_time,
                    zone=zone,
                    horizon_hours=horizon,
                    baseline_prediction=baseline_pred,
                    enhanced_prediction=enhanced_pred,
                    lightgbm_prediction=lightgbm_pred,
                    confidence_intervals=confidence_intervals,
                    forecast_improvement_pct=improvement_pct,
                    prediction_metadata={
                        'prediction_made_at': prediction_time,
                        'forecast_features_available': forecast_available,
                        'baseline_model_available': self.baseline_model is not None,
                        'enhanced_model_available': self.enhanced_model is not None,
                        'lightgbm_model_available': self.lightgbm_model is not None
                    }
                )
                
                results.append(result)
                
                logger.debug(f"Prediction for {horizon}h: baseline={baseline_pred:.1f}, enhanced={enhanced_pred:.1f}")
            
            logger.info(f"Generated {len(results)} predictions for {zone}")
            return results
            
        except Exception as e:
            raise PredictionError(f"Failed to make predictions: {e}")
    
    def generate_forecast_report(
        self,
        predictions: List[PredictionResult]
    ) -> Dict[str, any]:
        """
        Generate comprehensive forecast report with performance analysis.
        
        Args:
            predictions: List of prediction results
            
        Returns:
            Dictionary with forecast report data
        """
        logger.info("Generating forecast report")
        
        report = {
            'generated_at': datetime.now(timezone.utc).isoformat(),
            'total_predictions': len(predictions),
            'zones': list(set(p.zone for p in predictions)),
            'horizons': list(set(p.horizon_hours for p in predictions)),
            'forecast_availability': {},
            'performance_summary': {},
            'predictions': []
        }
        
        # Analyze forecast availability
        with_forecasts = [p for p in predictions if p.prediction_metadata.get('forecast_features_available', False)]
        report['forecast_availability'] = {
            'predictions_with_forecasts': len(with_forecasts),
            'predictions_without_forecasts': len(predictions) - len(with_forecasts),
            'forecast_coverage_pct': (len(with_forecasts) / len(predictions)) * 100 if predictions else 0
        }
        
        # Analyze performance improvements
        valid_improvements = [p.forecast_improvement_pct for p in predictions if p.forecast_improvement_pct is not None]
        if valid_improvements:
            report['performance_summary'] = {
                'mean_improvement_pct': np.mean(valid_improvements),
                'median_improvement_pct': np.median(valid_improvements),
                'std_improvement_pct': np.std(valid_improvements),
                'min_improvement_pct': np.min(valid_improvements),
                'max_improvement_pct': np.max(valid_improvements),
                'predictions_with_improvement': len([x for x in valid_improvements if x > 0]),
                'target_improvement_achieved': np.mean([abs(x) for x in valid_improvements]) >= 5.0
            }
        
        # Add individual predictions
        for pred in predictions:
            report['predictions'].append({
                'timestamp': pred.timestamp.isoformat(),
                'zone': pred.zone,
                'horizon_hours': pred.horizon_hours,
                'baseline_prediction': pred.baseline_prediction,
                'enhanced_prediction': pred.enhanced_prediction,
                'improvement_pct': pred.forecast_improvement_pct,
                'forecast_available': pred.prediction_metadata.get('forecast_features_available', False)
            })
        
        return report
    
    def run_realtime_demo(self) -> Dict[str, any]:
        """
        Run a demonstration of real-time forecasting capabilities.
        
        Returns:
            Dictionary with demonstration results
            
        Raises:
            PredictionError: If demonstration fails
        """
        logger.info("ðŸš€ Running real-time forecasting demonstration")
        
        if not self.is_initialized:
            self.initialize()
        
        try:
            current_time = datetime.now(timezone.utc)
            all_predictions = []
            
            # Generate predictions for each configured zone
            for zone in self.config.target_zones:
                zone_predictions = self.make_predictions(
                    prediction_time=current_time,
                    zone=zone,
                    horizons=self.config.prediction_horizons
                )
                all_predictions.extend(zone_predictions)
            
            # Generate comprehensive report
            report = self.generate_forecast_report(all_predictions)
            
            logger.info("âœ… Real-time forecasting demonstration completed")
            logger.info(f"Generated {len(all_predictions)} predictions across {len(self.config.target_zones)} zones")
            
            return report
            
        except Exception as e:
            raise PredictionError(f"Real-time demonstration failed: {e}")
